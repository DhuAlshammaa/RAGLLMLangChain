{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain and related imports\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    WebBaseLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e418f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = [\n",
    "    \"docs/test_rag.pdf\",\n",
    "    \"docs/test_rag.docx\",\n",
    "    \"docs/Document 4.pdf\"\n",
    "]\n",
    "\n",
    "docs =[]\n",
    "for doc_file in doc_path: \n",
    "    file_path = Path(doc_file)\n",
    "    try: \n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Documents type {file_path.type} not supported.\")\n",
    "            continue\n",
    "        # Make the Docs in one object has all the Docs\n",
    "        docs.extend(loader.load())\n",
    "    except Exception as e : \n",
    "        print(f\"Error loading the document {doc_file}: {e}\")\n",
    "    \n",
    "  #  finally:\n",
    "      #  os.remove(file_path)\n",
    "\n",
    "    #Load webs URLs\n",
    "\n",
    "web_urls = [\n",
    "    \"https://docs.streamlit.io/develop/quick-reference/release-notes\",\n",
    "    \n",
    "]\n",
    "\n",
    "# Container for all loaded documents\n",
    "docs = []\n",
    "\n",
    "# Load local files\n",
    "for doc_file in doc_path: \n",
    "    file_path = Path(doc_file)\n",
    "    try: \n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Document type {file_path.suffix} not supported.\")\n",
    "            continue\n",
    "        docs.extend(loader.load())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the document {doc_file}: {e}\")\n",
    "\n",
    "# Load URLs\n",
    "for url in web_urls:\n",
    "    try:\n",
    "        loader = WebBaseLoader(url)\n",
    "        docs.extend(loader.load())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document from {url}: {e}\")\n",
    "\n",
    "# Optional: view result\n",
    "print(f\"Total documents loaded: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the files to chunks \n",
    "#The recursive splitter will try to chunk it at:\n",
    "# The recursive splitter will try to chunk it at:\n",
    "# Paragraph breaks first\n",
    "# Then sentence boundaries\n",
    "# Then newlines\n",
    "# Then spaces\n",
    "# Then finally by character count if necessary\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=1000,\n",
    ")\n",
    "documents_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002aea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Tokenization vs. Embedding â€” Explained\n",
    "# ðŸŸ¦ Tokenization\n",
    "# What it is: Splitting text into smaller units called tokens (e.g., words, subwords, or even characters).\n",
    "\n",
    "# Why itâ€™s used: Language models like GPT or BERT don't read raw text â€” they process tokens.\n",
    "\n",
    "# Example:\n",
    "\n",
    "# text\n",
    "# Copy\n",
    "# Edit\n",
    "# Input: \"I love pizza\"\n",
    "# Tokens: [\"I\", \" love\", \" pizza\"]\n",
    "# âœ… Tokenization is like turning sentences into ID numbers the model can understand.\n",
    "\n",
    "# ðŸŸ© Embedding\n",
    "# What it is: Mapping each token (or whole sentence) to a vector of numbers that captures its meaning.\n",
    "\n",
    "# Why itâ€™s used: Embeddings let models compare meanings, search for similarity, and reason.\n",
    "\n",
    "# Types:\n",
    "\n",
    "# Word embeddings (like Word2Vec, GloVe)\n",
    "\n",
    "# Sentence/document embeddings (like OpenAIâ€™s text-embedding-3-small)\n",
    "\n",
    "# Example:\n",
    "\n",
    "# text\n",
    "# Copy\n",
    "# Edit\n",
    "# Token: \"pizza\" â†’ Embedding: [0.27, -0.41, 0.89, ...]\n",
    "# ðŸ”„ Workflow Relationship\n",
    "# In a typical NLP pipeline:\n",
    "\n",
    "# scss\n",
    "# Copy\n",
    "# Edit\n",
    "# Text â†’ Tokenization â†’ Tokens â†’ Embedding â†’ Vector(s)\n",
    "# Tokenization: turns text into symbols (tokens)\n",
    "\n",
    "# Embedding: turns symbols into meaning (vectors)\n",
    "\n",
    "# ðŸ§© In LangChain or RAG:\n",
    "# Tokenization affects chunking and cost estimation (e.g., 4096 token limits).\n",
    "\n",
    "# Embedding is used for vector search and similarity (e.g., searching documents by meaning).\n",
    "\n",
    "# âœ… Summary Table:\n",
    "# Feature\tTokenization\tEmbedding\n",
    "# Purpose\tBreak text into tokens\tMap tokens/text into numeric vectors\n",
    "# Output\tList of tokens (strings or IDs)\tVectors (arrays of floats)\n",
    "# Used for\tInput to models\tSemantic similarity, search\n",
    "# Tools\ttiktoken, HuggingFace Tokenizers\tOpenAI Embedding API, SentenceTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After we done with Split the documents to chunks \n",
    "# We will use tokenizer to trasfer this chunks to token \n",
    "# Token means we will still have the words but \n",
    "# We will trasfer the words to token \n",
    "# 1 toke can be one world more than one word and may be part of a word \n",
    "\n",
    "#  Rough Estimate (for English & GPT models)\n",
    "# 1 token â‰ˆ 3 to 4 characters (letters)\n",
    "\n",
    "# 1 token â‰ˆ 0.75 words\n",
    "\n",
    "# 100 tokens â‰ˆ 75 words â‰ˆ 300â€“400 characters\n",
    "\n",
    "\n",
    "\n",
    "vector_db = Chroma.from_documents (\n",
    "    documents = documents_chunks,\n",
    "    embedding = OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# ðŸŸ¢ 1. Chroma.from_documents(...)\n",
    "# This is a class method that:\n",
    "\n",
    "# Takes a list of documents (your split chunks)\n",
    "\n",
    "# Converts them into vector embeddings using the provided embedding model\n",
    "\n",
    "# Stores them in a ChromaDB instance (either in-memory or on disk)\n",
    "\n",
    "# This allows you to later search for similar documents using vector similarity (like cosine similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35667acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the retriver chat and documents \n",
    "def _get_context_retriever_chain (vector_db, llm):\n",
    "    #This turns your Chroma DB into a retriever object. LangChain uses this for semantic search over embeddings.\n",
    "    retriever = vector_db.as_retriever()\n",
    "\n",
    "    #This block defines the prompt that the LLM will see when it's generating a search query.\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            (\"user\",\"Given the above conversation,generate a search query to look up in order to n\\\n",
    "            get information relevant to the conversation, focusing on the most recent message.\"),\n",
    "            ])\n",
    "    retriever_chain = create_history_aware_retriever ( llm, retriever, prompt)\n",
    "\n",
    "    return retriever_chain #  this chain returns a retriever chain (not string). It returns Runnable that gives relevant Document objects based on message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this for complete RAG chain \n",
    "def get_conversational_rag_chain(llm):\n",
    "    #Output of this step: a LangChain retriever chain that returns List[Document]\n",
    "    retriever_chain = _get_context_retriever_chain (vector_db, llm)\n",
    "    #{context} placeholder that gets filled with relevant docs\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\" ,\n",
    "        \"\"\"You are a helpful assistant. Ypu will have to answer to user's queries \n",
    "        You will have some context to help with your answer, but now always would be completely related or helpful.\n",
    "        You can also use your knowledge to assit answering the user's queries.\\n            \n",
    "        {context}\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ])\n",
    "    # the output of stuff_documents_chain will be a string\n",
    "    stuff_documents_chain = stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)\n",
    "    #Date 07/27/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c63e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agmented Generation \n",
    "\n",
    "llm_stream_openai = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream_anthropic = ChatAnthropic(\n",
    "    model=\"claude-.-5-sonnet\",\n",
    "    temperature =0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream =llm_stream_openai \n",
    "\n",
    "messages = [\n",
    "    {\"role\" : \"user\",\"content\":\"Hi\"},\n",
    "    {\"role\" : \"assistant\", \"content\": \"Hi there! How can I assist you today ? \"},\n",
    "    {\"role\" : \"user\", \"content\" : \"what the company name Im trying to apply to\" },\n",
    "]\n",
    "\n",
    "messages = [HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"]) for m in messages]\n",
    "\n",
    "conversation_rag_chain = get_conversational_rag_chain(llm_stream)\n",
    "response_message = \"*(RAG Response)*\\n\"\n",
    "for chunk in conversation_rag_chain.pick(\"answer\").stream({\"messages\": messages[:-1], \"input\":messages[-1].content}):\n",
    "    response_message += chunk \n",
    "    print(chunk,end=\"\", flush =True)\n",
    "    messages.append({\"role\": \"assistant\",\"content\": response_message})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd6b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
